{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlpc.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/krm+g2o+K2AhYLEtg2+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anniebbii/bork/blob/master/mlpc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThAMyermEL_a"
      },
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# take care of missing values?\n",
        "# identify outliers? (missed comma, extra 0 etc.)\n",
        "# standardize inputs?\n",
        "\n",
        "# data before cleaning:\n",
        "# y is names ['Bob' 'Atsuto' 'Jörg' ' ooh'] only one ' ooh'\n",
        "# x5 is true/false ['False' 'True' '?' 'F' nan], two '?', one 'F', one nan\n",
        "# x6 is letters ['F' 'E' 'A' 'D' 'B' 'Fx' 'C' '-0.46960' nan] only one '-0.4...', one nan\n",
        "\n",
        "# import data as pandas dataframe\n",
        "#df = pd.read_csv(\"TrainOnMe.csv\")\n",
        "url = 'https://raw.githubusercontent.com/anniebbii/mlpc/main/TrainOnMe.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# remove rows with weird entries since they're few and we got enough data\n",
        "df = df.drop(df[df.y == ' ooh'].index)\n",
        "df = df.drop(df[df.x5 == '?'].index)\n",
        "df = df.drop(df[df.x5 == 'F'].index)\n",
        "df = df.drop(df[df.x6 == '-0.46960'].index)\n",
        "#df = df.dropna(axis=0, how='any')  # drop rows containing any null values\n",
        "\n",
        "# encode categorical variables\n",
        "df = df.replace('True', 1)\n",
        "df = df.replace('False', 0)\n",
        "df = df.replace('F', -1)\n",
        "df = df.replace('Fx', 0)\n",
        "df = df.replace('E', 1)\n",
        "df = df.replace('D', 2)\n",
        "df = df.replace('C', 3)\n",
        "df = df.replace('B', 4)\n",
        "df = df.replace('A', 5)\n",
        "# encode labels\n",
        "df = df.replace('Atsuto', 0)\n",
        "df = df.replace('Bob', 1)\n",
        "df = df.replace('Jörg', 2)\n",
        "\n",
        "# change column types\n",
        "df = df.astype({\"x1\": float, \"x2\": float})\n",
        "\n",
        "#print(df.head())\n",
        "#print(df.info())\n",
        "#print(df.describe())\n",
        "\n",
        "# separate features and labels\n",
        "# separate train/validation and test data\n",
        "X = df.iloc[:, 2:]\n",
        "y = df.iloc[:, 1]\n",
        "\n",
        "# split into train and validation data for cross validation\n",
        "X, X_ttest, y, y_ttest = train_test_split(X, y, test_size=0.1, random_state=123)\n",
        "\n",
        "# clean test data\n",
        "#for key in test:\n",
        "#    print(test[key].unique())\n",
        "# seems pretty clean\n",
        "\n",
        "#print(test.info()) # it's freeking purrfect\n",
        "#X_test = test.iloc[:, 1:]\n",
        "#print(X_test.head())"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BUmWqjqS3W9",
        "outputId": "f80a0fcb-0b75-4fc0-8a3a-436ec831eb3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from scipy import stats\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def test_strategy(X, y):\n",
        "  clf_xgb = XGBClassifier(objective = 'multi:softprob')\n",
        "  param_dist = {'learning_rate': [.01, 0.15],\n",
        "                'max_depth': [5],\n",
        "                'alpha': [3, 5],\n",
        "                'n_estimators': [20, 25, 30],\n",
        "                'colsample_bytree': [0.4, 0.5, 0.6]}\n",
        "\n",
        "  clf = GridSearchCV(clf_xgb, param_grid = param_dist, scoring = 'accuracy',  # create grid-search with 5-fold CV\n",
        "                    error_score = 0, verbose = 0, n_jobs = -1)\n",
        "\n",
        "  numFolds = 10\n",
        "  folds = KFold(n_splits = numFolds, shuffle = True)\n",
        "\n",
        "  scores = []\n",
        "  for train_index, test_index in folds.split(X):                                                  # for each k\n",
        "      X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]                               # create training set T_k\n",
        "      y_train, y_test = y.iloc[train_index].values.ravel(), y.iloc[test_index].values.ravel()     # and validation set V_k\n",
        "      clf.fit(X_train, y_train)                                                                   # do grid search CV                                                    # then pick best model\n",
        "      preds = clf.predict(X_test)                                                                 # and test its accuracy\n",
        "      score = accuracy_score(y_test, preds)                                                       # on validation data\n",
        "      scores.append(score)\n",
        "  return scores\n",
        "\n",
        "\n",
        "numFolds = 10\n",
        "folds = KFold(n_splits = numFolds, shuffle = True)\n",
        "\n",
        "mid_scores = []\n",
        "ytterst = []\n",
        "for train_index, test_index in folds.split(X):                                                  # for each k\n",
        "      X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]                               # create training set T_k\n",
        "      y_train, y_test = y.iloc[train_index].values.ravel(), y.iloc[test_index].values.ravel()     # and validation set V_k\n",
        "      mid_scores.append(test_strategy(X_train, y_train))                                          # do grid search CV\n",
        "\n",
        "      mid_model = clf.fit(X_train, Y_train)                                                       # then pick best model\n",
        "      preds = clf.predict(X_test)                                                                 # and test its accuracy\n",
        "      score = accuracy_score(y_test, preds)                                                       # on validation data\n",
        "      scores.append(score)\n",
        "  return scores\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8662297128589262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}